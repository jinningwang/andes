{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RTED-TDS Co-Sim\n",
    "\n",
    "This notebook is used to implement the Co-Simulation of Real Time Economic Dispatch (RTED) and Time-Domain Simulation (TDS).\n",
    "In the RTED, SFR is considered. In the TDS, AGC is implemented.\n",
    "\n",
    "RTED is seperated into two DCOPF and ACOPF: 1) DCOPF with SFR is solved in gurobipy, which is packaged into the class ``rted`` in the file ``rted.py``. 2) ACOPF is solved in pandapower.\n",
    "\n",
    "Class ``rted`` has attributes ``rted`` and ``dcopf``. The two attributes are the RTED model and standard DCOPF model.\n",
    "The two model can be built by methods ``build_rted()`` and ``build_dcopf()``, respectively. The results can be accessed by method ``get_res()``, after successfully solved the ``rted`` or ``dcopf``.\n",
    "\n",
    "Table of contents:\n",
    "- Import case: import ADNES case\n",
    "- Load synthetic: build load curve as a scalar\n",
    "- Setup ``ssp`` and ``ssd``\n",
    "- Prepare: define some functions\n",
    "- Define param: define RTED loop parameters\n",
    "- Loop: Co-Sim loop\n",
    "\n",
    "List of major vars:\n",
    "\n",
    "- ``ssa`` ANDES system\n",
    "- ``ssp`` pandapower net\n",
    "- ``ssd`` DCOPF instance\n",
    "- ``sse`` EV aggregator\n",
    "\n",
    "Things need to be done when switching to other cases:\n",
    "- Assign generator cost data. The rows of gen_cost array should be the same with the length of ``ssp.gen``\n",
    "  including those uncontrollable ones, so the DCOPF model can build correctly.\n",
    "- Define generator controllability of ``ssp``, all generators are controllable by default\n",
    "- Define power system data: SFR cost, ramp limit (5-min-based)\n",
    "- Define generator type in ``ssd``, default as type I. For type I generator, generator limtis have impact on both generation and SFR capacity. For yype II generator, SFR capacity is determined by param ``pru_max`` and ``prd_max``\n",
    "\n",
    "Environment requirements:\n",
    "- ANDES (1.6.3+)\n",
    "- pandapower (2.7.0 is tested to be function correctly)\n",
    "- gurobipy\n",
    "- pandas, amtplotlib, scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T14:50:27.821845Z",
     "start_time": "2021-03-20T14:50:27.457672Z"
    },
    "execution": {
     "iopub.execute_input": "2021-09-26T22:41:51.096056Z",
     "iopub.status.busy": "2021-09-26T22:41:51.095687Z",
     "iopub.status.idle": "2021-09-26T22:41:51.787388Z",
     "shell.execute_reply": "2021-09-26T22:41:51.787697Z"
    }
   },
   "outputs": [],
   "source": [
    "import andes\n",
    "import numpy as np\n",
    "from andes.interop.pandapower import to_pandapower, make_link_table, runopp_map\n",
    "from andes.interop.pandapower import add_gencost, build_group_table\n",
    "andes.config_logger(stream_level=20)\n",
    "\n",
    "import pandas as pd\n",
    "import pandapower as pp\n",
    "from math import ceil, floor\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.stats as stat\n",
    "\n",
    "from jams import rted2, dcopf, rted3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ev_ssm import ev_ssm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Package version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0.post153+g04be8796\n",
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "print(andes.__version__)\n",
    "print(pp.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EV aggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse = ev_ssm(ts=10, N=10000, step=1, tp=100,\n",
    "             lr=0.1, lp=100, seed=2022, name=\"EVA\")\n",
    "sse.load_A(\"Aest.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import ADNES case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T14:50:33.843520Z",
     "start_time": "2021-03-20T14:50:33.664077Z"
    },
    "execution": {
     "iopub.execute_input": "2021-09-26T22:41:59.401976Z",
     "iopub.status.busy": "2021-09-26T22:41:59.401670Z",
     "iopub.status.idle": "2021-09-26T22:41:59.781185Z",
     "shell.execute_reply": "2021-09-26T22:41:59.780928Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Working directory: \"/Users/jinningwang/Documents/work/andes/jwang/notes2\"\n",
      "> Loaded config from file \"/Users/jinningwang/.andes/andes.rc\"\n",
      "> Loaded generated Python code in \"/Users/jinningwang/.andes/pycode\".\n",
      "Parsing input file \"/Users/jinningwang/Documents/work/andes/jwang/case/ieee39_ev2.xlsx\"...\n",
      "Input file parsed in 0.1314 seconds.\n",
      "ACEc <1> added BusFreq <BusFreq_11> linked to bus <1>\n",
      "System internal structure set up in 0.0227 seconds.\n",
      "Working directory: \"/Users/jinningwang/Documents/work/andes/jwang/notes2\"\n",
      "> Loaded config from file \"/Users/jinningwang/.andes/andes.rc\"\n",
      "> Reloaded generated Python code of module \"pycode\".\n",
      "Parsing input file \"/Users/jinningwang/Documents/work/andes/jwang/case/ieee39_ev2.xlsx\"...\n",
      "Input file parsed in 0.0635 seconds.\n",
      "ACEc <1> added BusFreq <BusFreq_11> linked to bus <1>\n",
      "System internal structure set up in 0.0249 seconds.\n"
     ]
    }
   ],
   "source": [
    "# ss0 is used for PP conversion\n",
    "dir_path = os.path.abspath('..')\n",
    "case_path = '/case/ieee39_ev2.xlsx'\n",
    "case = dir_path + case_path\n",
    "ssa = andes.load(case,\n",
    "                 setup=True,\n",
    "                 no_output=True,\n",
    "                 default_config=False)\n",
    "ss0 = andes.load(case,\n",
    "                 setup=True,\n",
    "                 no_output=True,\n",
    "                 default_config=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set output mode as 'manual'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssa.TDS.config.save_mode = 'manual'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set load as constant load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssa.PQ.config.p2p = 1\n",
    "ssa.PQ.config.q2q = 1\n",
    "ssa.PQ.config.p2z = 0\n",
    "ssa.PQ.config.q2z = 0\n",
    "ssa.PQ.pq2z = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn on ``numba`` can accelerate TDS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssa.config.numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load synthetic\n",
    "\n",
    "Create load data ``d_syn``, which is a ``DataFrame`` that have three columns: ``time``, ``s10``, ``h10``. ``time`` is by seconds, ``s10`` is scalar load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --- get ANDES load ---\n",
    "ptotal = ssa.PQ.as_df()['p0'].sum()\n",
    "print('ANDES total load is:',ptotal.round(4),'p.u.')\n",
    "\n",
    "# --- scale d_syn ---\n",
    "ddata_path = '/case/d_syn2.csv'\n",
    "ddata = dir_path + ddata_path\n",
    "d_syn = pd.read_csv(ddata)\n",
    "\n",
    "ratio = 5\n",
    "# The equation is tuned for ieee39\n",
    "# original: (d_syn['h10'] - d_syn['h10'].mean()) / d_syn['h10'].var() * ratio + 1\n",
    "d_syn['s10'] = ratio*(d_syn['ph10'] - d_syn['ph10'].min()) / d_syn['h10'].var() + 1\n",
    "\n",
    "# calculate expected load\n",
    "step = 300\n",
    "d_exp = d_syn.groupby(d_syn.index // step).mean().copy()\n",
    "d_exp['time'] = range(0,3600,300)\n",
    "\n",
    "fig_load, ax_load = plt.subplots(figsize=(5, 4))\n",
    "ax_load.plot(d_syn['time'], d_syn['s10'], color='tab:blue', linestyle='-')\n",
    "ystep = list(d_exp['s10'])\n",
    "ystep.insert(0, d_exp['s10'].iloc[0])\n",
    "ax_load.step(range(0,3900,300), ystep, color='tab:blue', linestyle='--')\n",
    "ax_load.set_xlim([0, 3600])\n",
    "ax_load.legend(['Actual load', 'Forecasted load'])\n",
    "ax_load.set_title('Load profile')\n",
    "ax_load.set_ylabel('ratio')\n",
    "ax_load.set_xlabel('Time [s]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup ``ssp`` and ``ssd``\n",
    "\n",
    "Convert ``ssa`` to pandapower net ``ssp``, add generator cost\n",
    "\n",
    "The input cost array follow the matpower/pypower format, now only poly_cost is supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- conversion ---\n",
    "ssp = to_pandapower(ss0)\n",
    "\n",
    "# set EV generator as uncontrollable\n",
    "ssp.gen.controllable.iloc[9] = False\n",
    "\n",
    "# add gen cost, G1-11. G10 EV, G11 Slack\n",
    "linearcost = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.5]\n",
    "\n",
    "gen_cost = np.array([[2., 0., 0., 3., 0., 0., 0.]] * ssp.gen.shape[0])\n",
    "gen_cost[:, 5] = linearcost  # c1\n",
    "\n",
    "add_gencost(ssp, gen_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ssp.gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build RTED instance ``ssd``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ssd = rted3()\n",
    "ssd.from_andes(ss0)\n",
    "\n",
    "# set EV generator as uncontrollable\n",
    "ssd.gen.ctrl.iloc[9] = 0\n",
    "\n",
    "# set EV geenrator as type2\n",
    "ssd.def_type2(['PV_10'], [0], [0])\n",
    "\n",
    "# set ramp5\n",
    "ramp_hour = [999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999]\n",
    "# ramp_hour = [80, 80, 80, 50, 50, 50, 30, 30, 30, 999, 30]\n",
    "ssd.gen.ramp5 = np.array(ramp_hour) * 10 / 12 / ssd.mva\n",
    "\n",
    "# set cost\n",
    "ssd.cost.c1 = linearcost\n",
    "\n",
    "# update p_pre from DCOPF results\n",
    "ssd.set_p_pre()\n",
    "\n",
    "# sovle the model\n",
    "ssd.get_res()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark Standard DCOPF of ``ssd`` with ``ssp``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pp.rundcopp(ssp)\n",
    "ppres = ssp.res_gen.copy()\n",
    "ssdc = ssd.to_dcopf()\n",
    "gb_res = ssdc.get_res()\n",
    "ppres['p_mw(GB)'] = ssp.sn_mva * gb_res['pg'].values\n",
    "print(f\"pp cost={ssp.res_cost}, gb cost={ssd.res_cost}\")\n",
    "ppres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make link table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- link_table ---\n",
    "ssa_key = make_link_table(ssa)\n",
    "\n",
    "# --- add controllable in the link table ---\n",
    "ssa_bus = ssa.Bus.as_df().reset_index().rename(columns={'uid':'bus_pp', 'idx':'bus_idx'})\n",
    "ssp_gen = ssp.gen.reset_index().rename(columns={'index':'gen_pp', 'name':'stg_idx', 'controllable':'ctrl'})\n",
    "ssa_key2 = pd.merge(left=ssa_key,\n",
    "                    right=ssp_gen[['stg_idx', 'gen_pp', 'ctrl']],\n",
    "                    on='stg_idx', how='left')\n",
    "\n",
    "# --- device idx ---\n",
    "ssa_dg_idx = ssa_key2.dg_idx.dropna().tolist()\n",
    "ssa_syg_idx = ssa_key2.syg_idx.dropna().tolist()\n",
    "ssa_gov_idx = ssa_key2.gov_idx.dropna().tolist()\n",
    "ssa_stg_idx = ssa_key2.stg_idx.dropna().tolist()\n",
    "\n",
    "# --- online and controllable device idx ---\n",
    "ctrl_cond = ssa_key2.ctrl & ssa_key2.stg_u.astype(bool)\n",
    "ssa_dg_idx_ctrl = ssa_key2.dg_idx[ctrl_cond].dropna().tolist()\n",
    "ssa_syg_idx_ctrl = ssa_key2.syg_idx[ctrl_cond].dropna().tolist()\n",
    "ssa_gov_idx_ctrl = ssa_key2.gov_idx[ctrl_cond].dropna().tolist()\n",
    "ssa_stg_idx_ctrl = ssa_key2.stg_idx[ctrl_cond].dropna().tolist()\n",
    "\n",
    "# fill NaN with False\n",
    "ssa_key2.fillna(value=False, inplace=True)\n",
    "\n",
    "ssa_key2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions used in loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- def functions ---\n",
    "def get_pe(ssa, gov_idx, dg_idx, ssa_key2):\n",
    "    \"\"\"Get the active power (TurbineGov/DG) after TDS, a DataFrame\"\"\"\n",
    "    # TODO: may need to sum the power of same StaticGen\n",
    "    # --- TurbineGov --- \n",
    "    pe_syg = ssa.TurbineGov.get(src='pout', idx=gov_idx, attr='v')\n",
    "    # --- DG ---\n",
    "    Ip_dg = ssa.DG.get(src='Ipout_y', idx=dg_idx, attr='v')\n",
    "    v_dg = ssa.DG.get(src='v', idx=dg_idx, attr='v')\n",
    "    pe_dg = Ip_dg*v_dg\n",
    "    # --- out ---\n",
    "    pe = pd.DataFrame()\n",
    "    pe['idx'] = gov_idx + dg_idx\n",
    "    pe['pe'] = np.concatenate((pe_syg, pe_dg))\n",
    "    ldf = pd.merge(left=ssa_key2.rename(columns={'dg_idx':'idx'}),\n",
    "         right=pe, how='right', on='idx')\n",
    "    rdf = pd.merge(left=ssa_key2.rename(columns={'gov_idx':'idx'}),\n",
    "             right=pe, how='right', on='idx')\n",
    "    pe['stg_idx'] = ldf['stg_idx'].fillna('') + rdf['stg_idx'].fillna('')\n",
    "    return pe\n",
    "\n",
    "def dp_calc(d_syn, idx_ed, intv_ed):\n",
    "    \"\"\"Calc SFR requirements, scalars, ``dpd_u``and ``dpd_d``, and load forecasted value ``load_exp``\"\"\"\n",
    "    load = d_syn['s10'].iloc[idx_ed*intv_ed:(idx_ed*intv_ed + intv_ed)]\n",
    "    load_exp = load.mean()\n",
    "    # TODO: check if the estimation is reasonable\n",
    "    ratio = 50\n",
    "    load_ci = stat.t.interval(alpha=0.95, df=len(load)-1, loc=np.mean(load), scale=stat.sem(load))\n",
    "    load_d = abs(load_ci[0] - load_exp) * ratio\n",
    "    load_u = abs(load_ci[1] - load_exp) * ratio\n",
    "    return load_u, load_d, load_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- constants ---\n",
    "t_total = 3600    # 3600s\n",
    "\n",
    "intv_ed = 300  # RTED interval, 300s\n",
    "intv_agc = 4    # AGC interval, 4s\n",
    "intv_pq = 1     # PQ interval, 1s; alter load and AGC\n",
    "intv_step = 100 # step change interval; smooth the setpoitns\n",
    "\n",
    "n_ed = int(t_total/intv_ed)\n",
    "n_agc = int(intv_ed/intv_agc)\n",
    "n_pq = int(intv_agc/intv_pq)\n",
    "n_step = floor(intv_step/intv_agc)\n",
    "\n",
    "# --- vars ---\n",
    "# AGC table\n",
    "agc_table = ssp.gen[['name']].rename(columns={'name':'stg_idx'})\n",
    "agc_table['paux'] = 0\n",
    "agc_res = agc_table[['stg_idx']].copy()\n",
    "\n",
    "# ACE vars\n",
    "ACE_integral = 0\n",
    "ACE_raw = 0\n",
    "Kp = 0.5 # 0.05\n",
    "Ki = 0.0\n",
    "ace_res = pd.DataFrame()\n",
    "\n",
    "# initial load\n",
    "ssa_p0 = ssa.PQ.p0.v.copy()\n",
    "ssa_q0 = ssa.PQ.q0.v.copy()\n",
    "ssa_pq_idx = ssa.PQ.idx.v\n",
    "ssa_p0_sum = ssa_p0.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop\n",
    "\n",
    "In the loop, there are mainly X parts:\n",
    "\n",
    "- interval RTED: run DCOPF (``ssd.mdl``), run ACOPF(``ssp``), \n",
    "\n",
    "- interval AGC: do AGC, do dispatch with smooth setpoints\n",
    "\n",
    "- interval PQ: alter load, run TDS(``ssa.TDS``)\n",
    "\n",
    "Notes:\n",
    "\n",
    "- The setpoints for DG are coded but not verified yet.\n",
    "\n",
    "- After the development of ANDES control room, the dispatch and AGC part can be refactored.\n",
    "\n",
    "- interface variables: ``DG.pmx``: DPV profile, ``DG.pref0``: setpoints, ``DG.pext0``: AGC\n",
    "\n",
    "- ACOPF in pandapower considered generator limtis of ramping and SFR reserve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if RTED converge in all 12 intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reserve some capacity to avoid TDS crush\n",
    "ssp.gen.max_p_mw = ssp.gen.max_p_mw * 1\n",
    "\n",
    "# store original generator data\n",
    "ssp_gen0 = ssp.gen.copy()\n",
    "\n",
    "pgres = pd.DataFrame()\n",
    "\n",
    "for end_time in range(t_total): # t_total\n",
    "    # --- interval RTED ---\n",
    "    if end_time % intv_ed == 0:\n",
    "        idx_ed = end_time // intv_ed\n",
    "        # --- Load update ---\n",
    "        du, dd, load_exp = dp_calc(d_syn, idx_ed, intv_ed)\n",
    "        ssp.load['p_mw'] = ssa_p0 * ssp.sn_mva * load_exp\n",
    "        ssp.load['q_mvar'] = ssa_q0 * ssp.sn_mva * load_exp\n",
    "        ssd.load['p0'] = ssa_p0 * load_exp\n",
    "        ssd.update_dict()\n",
    "\n",
    "        # --- RTED, update gen limits after SFR ---\n",
    "        ssd.set_p_pre()\n",
    "        p_pre = ssd.gen[['idx', 'p_pre']].rename(columns={'p_pre':'pe', 'idx':'stg_idx'})\n",
    "\n",
    "        # def sfr requirements and ev sfr limtis (p.u.)\n",
    "        # TODO: Integrate EV; EV limits FROM EV; now set 0 to disable EV SFR\n",
    "        ssd.def_sfr(du=du*ssa_p0_sum, dd=dd*ssa_p0_sum)\n",
    "\n",
    "        # build and solve the RTED-DC\n",
    "        dcres = ssd.get_res()  # get RTED-DC resutls\n",
    "        # TODO: Integrate EV; send SFR back to EV\n",
    "\n",
    "        # Reserve SFR and ramp from Generator limits in ``ssp``\n",
    "        ssp_gen = pd.merge(left=ssp.gen.rename(columns={'name':'stg_idx'}),\n",
    "                           right=dcres.rename(columns={'gen':'stg_idx'}),\n",
    "                           on='stg_idx', how='left')\n",
    "        # SFR limits\n",
    "        ssp_gen['max_sfr'] = ssp_gen.max_p_mw - ssp_gen.pru * ssp.sn_mva\n",
    "        ssp_gen['min_sfr'] = ssp_gen.min_p_mw + ssp_gen.prd * ssp.sn_mva\n",
    "        # ramp limits\n",
    "        p_pre_pp = pd.merge(left=ssp.gen.rename(columns={'name': 'stg_idx'}),\n",
    "                            right=p_pre[['stg_idx', 'pe']],\n",
    "                            on='stg_idx', how='left')['pe']\n",
    "        ssp_gen['max_ramp'] = ssp.sn_mva * (np.array(p_pre_pp) + np.array(ssd.gen.ramp5))\n",
    "        ssp_gen['min_ramp'] = ssp.sn_mva * (np.array(p_pre_pp) - np.array(ssd.gen.ramp5))\n",
    "        # alter generator limits\n",
    "        ssp.gen.max_p_mw = ssp_gen[['max_sfr','max_ramp']].min(axis=1)\n",
    "        ssp.gen.min_p_mw = ssp_gen[['min_sfr','min_ramp']].max(axis=1)\n",
    "\n",
    "        # --- ACOPF, update setpoints ---\n",
    "        # store setpoints\n",
    "        if end_time > 0:\n",
    "            p0 = ssp_res['p'].values  # store setpoints\n",
    "        else:\n",
    "            p0 = [0] * ssa_key2.shape[0]\n",
    "\n",
    "        # run ACOPF\n",
    "        ssp_res = runopp_map(ssp, ssa_key)  # ACOPF resutls\n",
    "        ssp_res['p0'] = p0                  # last setpoints\n",
    "        ssp_res.fillna(False, inplace=True) # Fill NA wil False\n",
    "\n",
    "        # reset Generator limtis\n",
    "        ssp.gen.max_p_mw = ssp_gen0.max_p_mw\n",
    "        ssp.gen.min_p_mw = ssp_gen0.min_p_mw\n",
    "        \n",
    "        pgres[f'{idx_ed}'] = ssp_res.p\n",
    "\n",
    "pgres.sum().plot()\n",
    "pgres.T.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reserve some capacity to avoid TDS crush\n",
    "ssp.gen.max_p_mw = ssp.gen.max_p_mw * 1\n",
    "\n",
    "# store original generator data\n",
    "ssp_gen0 = ssp.gen.copy()\n",
    "\n",
    "for end_time in range(t_total): # t_total\n",
    "    # --- interval RTED ---\n",
    "    if end_time % intv_ed == 0:\n",
    "        idx_ed = end_time // intv_ed\n",
    "        # --- Load update ---\n",
    "        du, dd, load_exp = dp_calc(d_syn, idx_ed, intv_ed)\n",
    "        ssp.load['p_mw'] = ssa_p0 * ssp.sn_mva * load_exp\n",
    "        ssp.load['q_mvar'] = ssa_q0 * ssp.sn_mva * load_exp\n",
    "        ssd.load['p0'] = ssa_p0 * load_exp\n",
    "        ssd.update_dict()\n",
    "\n",
    "        # --- RTED, update gen limits after SFR ---\n",
    "        if end_time > 0:\n",
    "            # get pe from TDS and sort\n",
    "            pe_tds = get_pe(ssa, ssa_gov_idx, ssa_dg_idx, ssa_key2)\n",
    "            pe_tds = pe_tds.merge(ssa_key2,\n",
    "                                 on='stg_idx', how='right').groupby('stg_idx', as_index=False).sum()\n",
    "            p_pre = pe_tds\n",
    "            ssd.gen.p_pre = pd.merge(left=ssd.gen, how='left', on='idx',\n",
    "                         right=pe_tds[['stg_idx', 'pe']].rename(columns={'stg_idx': 'idx'}))['pe']\n",
    "        else:\n",
    "            # DCOPF results as the initial previous setpoints\n",
    "            ssd.set_p_pre()\n",
    "            p_pre = ssd.gen[['idx', 'p_pre']].rename(columns={'p_pre':'pe', 'idx':'stg_idx'})\n",
    "\n",
    "        # def sfr requirements and ev sfr limtis (p.u.)\n",
    "        # TODO: Integrate EV; EV limits FROM EV; now set 0 to disable EV SFR\n",
    "        ssd.def_sfr(du=du*ssa_p0_sum, dd=dd*ssa_p0_sum)\n",
    "\n",
    "        # build and solve the RTED-DC\n",
    "        dcres = ssd.get_res()  # get RTED-DC resutls\n",
    "        # TODO: Integrate EV; send SFR back to EV\n",
    "\n",
    "        # Reserve SFR and ramp from Generator limits in ``ssp``\n",
    "        ssp_gen = pd.merge(left=ssp.gen.rename(columns={'name':'stg_idx'}),\n",
    "                           right=dcres.rename(columns={'gen':'stg_idx'}),\n",
    "                           on='stg_idx', how='left')\n",
    "        # SFR limits\n",
    "        ssp_gen['max_sfr'] = ssp_gen.max_p_mw - ssp_gen.pru * ssp.sn_mva\n",
    "        ssp_gen['min_sfr'] = ssp_gen.min_p_mw + ssp_gen.prd * ssp.sn_mva\n",
    "        # ramp limits\n",
    "        p_pre_pp = pd.merge(left=ssp.gen.rename(columns={'name': 'stg_idx'}),\n",
    "                            right=p_pre[['stg_idx', 'pe']],\n",
    "                            on='stg_idx', how='left')['pe']\n",
    "        ssp_gen['max_ramp'] = ssp.sn_mva * (np.array(p_pre_pp) + np.array(ssd.gen.ramp5))\n",
    "        ssp_gen['min_ramp'] = ssp.sn_mva * (np.array(p_pre_pp) - np.array(ssd.gen.ramp5))\n",
    "        # alter generator limits\n",
    "        ssp.gen.max_p_mw = ssp_gen[['max_sfr','max_ramp']].min(axis=1)\n",
    "        ssp.gen.min_p_mw = ssp_gen[['min_sfr','min_ramp']].max(axis=1)\n",
    "\n",
    "        # --- ACOPF, update setpoints ---\n",
    "        # store setpoints\n",
    "        if end_time > 0:\n",
    "            p0 = ssp_res['p'].values  # store setpoints\n",
    "        else:\n",
    "            p0 = [0] * ssa_key2.shape[0]\n",
    "\n",
    "        # run ACOPF\n",
    "        ssp_res = runopp_map(ssp, ssa_key)  # ACOPF resutls\n",
    "        ssp_res['p0'] = p0                  # last setpoints\n",
    "        ssp_res.fillna(False, inplace=True) # Fill NA wil False\n",
    "\n",
    "        # reset Generator limtis\n",
    "        ssp.gen.max_p_mw = ssp_gen0.max_p_mw\n",
    "        ssp.gen.min_p_mw = ssp_gen0.min_p_mw\n",
    "\n",
    "    # --- interval AGC ---\n",
    "    ace_gain = 1\n",
    "    if end_time % intv_agc == 0:\n",
    "        idx_agc = end_time // intv_agc - idx_ed * n_agc\n",
    "        # --- AGC allocation, with a power cap ---\n",
    "        ACE_input = min(ACE_raw, dcres.pru.sum())\n",
    "        if ACE_raw >= 0:\n",
    "            ACE_input = min(ACE_raw, dcres.pru.sum())\n",
    "            agc_table['paux'] = ACE_input * ace_gain * dcres.bu.values\n",
    "        else:\n",
    "            ACE_input = max(ACE_raw, -1 * dcres.prd.sum())\n",
    "            agc_table['paux'] = ACE_input * ace_gain * dcres.bd.values\n",
    "        agc_res[f'{end_time}'] = agc_table['paux']\n",
    "        ace_data = [end_time, ACE_raw, dcres.pru.sum(),\n",
    "                    -1*dcres.prd.sum(), ACE_input]\n",
    "        ace_new = pd.DataFrame([ace_data], columns=['time', 'ace', 'up', 'dn', 'in'])\n",
    "        ace_res = pd.concat([ace_res, ace_new])\n",
    "\n",
    "        # --- Do AGC ---\n",
    "        # a.SynGen\n",
    "        agc_syg = pd.merge(left=agc_table,\n",
    "                           right=ssa_key2,\n",
    "                           on='stg_idx', how='right')\n",
    "        agc_syg['paux2'] = agc_syg.paux * agc_syg.gammap\n",
    "        cond_gov = agc_syg.ctrl * agc_syg.gov_idx.astype(bool)\n",
    "        agc_gov = agc_syg.gov_idx[cond_gov].tolist()\n",
    "        ssa.TurbineGov.set(src='paux0', idx=agc_gov, attr='v',\n",
    "                           value=agc_syg.paux2.values)\n",
    "        # b.DG\n",
    "        agc_dg = pd.merge(left=agc_table,\n",
    "                          right=ssa_key2,\n",
    "                          on='stg_idx', how='right')\n",
    "        agc_dg['paux2'] = agc_dg.paux * agc_dg.gammap\n",
    "        cond_dg = agc_dg.ctrl * agc_dg.dg_idx.astype(bool)\n",
    "        agc_dg_idx = agc_dg.dg_idx[cond_dg].tolist()\n",
    "        ssa.DG.set(src='pext0', idx=agc_dg_idx, attr='v',\n",
    "                           value=agc_dg.paux2.values)\n",
    "        \n",
    "        # --- smooth setpoints --- \n",
    "        if idx_ed == 0:\n",
    "            ssp_res['pref'] = ssp_res['p']\n",
    "        else:\n",
    "            print(\"SMOOTH\")\n",
    "            if idx_agc == 0:\n",
    "                # only record the pe from TDS in the first AGC interval\n",
    "                copy = ssp_res.merge(right=pe_tds[['pe', 'stg_idx']], on='stg_idx', how='left')\n",
    "                ssp_res['pe_tds'] = copy.pe\n",
    "            idx_step = min((end_time - idx_ed * intv_ed) // intv_agc + 1, n_step)\n",
    "            ssp_res['pref_step'] = ssp_res.p - ssp_res.pe_tds\n",
    "            # smooth change threshold: 0.1\n",
    "            large_index = ssp_res['pref_step'][abs(ssp_res['pref_step']) > 0.01].index\n",
    "            ssp_res['pref_delta'] = ssp_res['pref_step']\n",
    "            ssp_res['pref_delta'].iloc[large_index] = ssp_res['pref_step'].iloc[large_index] / n_step * idx_step\n",
    "            ssp_res['pref'] = ssp_res.pe_tds + ssp_res.pref_delta\n",
    "\n",
    "            # update SynGen setpoints\n",
    "            cond_gov = ssp_res.controllable & ssp_res.gov_idx.astype(bool)\n",
    "            ssa.TurbineGov.set(src='pref0', idx=ssp_res.gov_idx[cond_gov].tolist(),\n",
    "                               attr='v', value=ssp_res.pref[cond_gov].values)\n",
    "            # update DG setpoints\n",
    "            cond_dg = ssp_res.controllable & ssp_res.dg_idx.astype(bool)\n",
    "            ssa.DG.set(src='pref0', idx=ssp_res.dg_idx[cond_dg].tolist(),\n",
    "                       attr='v', value=ssp_res.pref[cond_dg].values)\n",
    "\n",
    "    # --- intv_pq: alter load, run TDS ---\n",
    "    if end_time == 0:\n",
    "        # Initially, alter StaticGen: p0 and q0, RUN power flow\n",
    "        stg_opf_idx = ssp_res.stg_idx[ssp_res.controllable].tolist()\n",
    "        stg_opf_val = ssp_res.p[ssp_res.controllable].tolist()\n",
    "        stg_opf_v = ssp_res.vm_pu[ssp_res.controllable].tolist()\n",
    "        ssa.StaticGen.set(src='p0', idx=stg_opf_idx, attr='v', value=stg_opf_val)\n",
    "        ssa.StaticGen.set(src='v0', idx=stg_opf_idx, attr='v', value=stg_opf_v)\n",
    "        ssa.PQ.set(src='p0', idx=ssa_pq_idx, attr='v',\n",
    "                   value=ssa_p0 * load_exp)\n",
    "        ssa.PQ.set(src='q0', idx=ssa_pq_idx, attr='v',\n",
    "                   value=ssa_q0 * load_exp)\n",
    "        ssa.PFlow.run()\n",
    "    else:\n",
    "        # Otherwise, alter Ppf and Qpf\n",
    "        ssa.PQ.set(src='Ppf', idx=ssa_pq_idx, attr='v',\n",
    "                    value=ssa_p0 * d_syn['s10'].iloc[end_time])\n",
    "        ssa.PQ.set(src='Qpf', idx=ssa_pq_idx, attr='v',\n",
    "                    value=ssa_q0 * d_syn['s10'].iloc[end_time])\n",
    "        \n",
    "    # RUN TDS\n",
    "    ssa.TDS.config.tf = end_time\n",
    "    if not end_time == 0:\n",
    "        ssa.TDS.run()\n",
    "    # ACE calculation\n",
    "    ACE_integral = ACE_integral + ssa.ACEc.ace.v.sum()\n",
    "    ACE_raw = -(Kp*ssa.ACEc.ace.v.sum() + Ki*ACE_integral)\n",
    "\n",
    "    # ACE_raw = 0  # delete when run TDS\n",
    "    # break loop if TDS run into error\n",
    "    if ssa.exit_code != 0:\n",
    "        raise ValueError(f\"TDS error! Exit with {ssa.exit_code}, end at {end_time}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp.res_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssa.TDS.plt.plot(ssa.TGOV1N.pref, a=(4,5,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# color=['tab:blue', 'tab:orange', 'tab:green',\n",
    "#        'tab:red', 'tab:purple']\n",
    "right=end_time\n",
    "\n",
    "fig_gen, ax_gen = plt.subplots(2, 3, figsize=(16, 8))\n",
    "plt.subplots_adjust(left=None, bottom=None, right=None,\n",
    "                    top=None, wspace=0.3, hspace=0.6)\n",
    "\n",
    "yheader = [f'G{i}' for i in range(1,11)]\n",
    "\n",
    "ssa.TDS.plt.plot(ssa.TGOV1N.pout,\n",
    "                 linestyles=['-'],\n",
    "                   yheader=yheader,\n",
    "                   legend=True, show=False, right=right,\n",
    "                   title=r'Generation (solid: pout; dash: pref)',\n",
    "                   ylabel='p.u.',\n",
    "                   fig=fig_gen, ax=ax_gen[0, 0])\n",
    "\n",
    "ssa.TDS.plt.plot(ssa.TGOV1N.pref,\n",
    "                 legend=False, show=False, right=right,\n",
    "                   linestyles=['--'],\n",
    "                   fig=fig_gen, ax=ax_gen[0, 0])\n",
    "\n",
    "ssa.TDS.plt.plot(ssa.TGOV1N.paux,\n",
    "                linestyles=['-'],\n",
    "                yheader=yheader,\n",
    "                legend=False, show=False, right=right,\n",
    "                title=r'AGC power',\n",
    "                ylabel='p.u.',\n",
    "                fig=fig_gen, ax=ax_gen[0, 1])\n",
    "\n",
    "ace_res.plot(linewidth=1,\n",
    "            fig=fig_gen, ax=ax_gen[0, 2],\n",
    "            x='time', y='ace',\n",
    "            title=f'AGC input and SFR capacity')\n",
    "ace_res.plot(linewidth=1,\n",
    "            fig=fig_gen, ax=ax_gen[0, 2],\n",
    "            x='time', y='in',)\n",
    "ace_res.plot(linewidth=1, color='k', linestyle='--',\n",
    "            fig=fig_gen, ax=ax_gen[0, 2],\n",
    "            x='time', y='up')\n",
    "ace_res.plot(linewidth=1, color='k', linestyle='--',\n",
    "            fig=fig_gen, ax=ax_gen[0, 2],\n",
    "            x='time', y='dn')\n",
    "ax_gen[0, 2].set_ylabel('p.u.')\n",
    "ax_gen[0, 2].legend(['ACE raw', 'AGC input', 'SFR capacity'])\n",
    "\n",
    "ssa.TDS.plt.plot(ssa.COI.omega,\n",
    "                 legend=False, show=False, right=right,\n",
    "                 linestyles=['-'],\n",
    "                 ytimes=60,\n",
    "                 title=r'COI Frequency',\n",
    "                 ylabel='Hz',\n",
    "                 fig=fig_gen, ax=ax_gen[1, 0])\n",
    "\n",
    "ssa.TDS.plt.plot(ssa.ACEc.ace,\n",
    "                 legend=False, show=False, right=right,\n",
    "                 linestyles=['-'],\n",
    "                 title=r'ACE',\n",
    "                 ylabel='p.u.',\n",
    "                 fig=fig_gen, ax=ax_gen[1, 1])\n",
    "\n",
    "font = {'family' : 'TimesNewRoma',\n",
    "        'weight' : '1',\n",
    "        'size'   : 12}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "ace_tds = ssa.dae.ts.y[:, ssa.ACEc.ace.a].reshape(-1).copy()\n",
    "ace_df = pd.DataFrame()\n",
    "ace_df['ace'] = ace_tds\n",
    "ace_df.plot(kind='kde', legend=False, linewidth=1,\n",
    "            fig=fig_gen, ax=ax_gen[1, 2],\n",
    "            title=f'ACE Density, mean={ace_df.ace.mean().round(4)}')\n",
    "ax_gen[1, 2].set(xlabel='Deviation [p.u.]', ylabel='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcres"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ef6cb5c8d99d66a3614f491d51fd40cd94c9138687df3d2045e3a510da5efc66"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('andes')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
